{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87363b4b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "<img src=\"https://mma.prnewswire.com/media/1095203/East_Tennessee_State_University_Logo.jpg?p=facebook\" width=200 height=200 />\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1 style=\"text-align: center\">CSCI 5037 - NLP & Text Analysis</h1>\n",
    "</div>\n",
    "\n",
    "# <center>Lab 2 - Text Cleaning </center>\n",
    "\n",
    "**<center>Dr. Ahmad Al-Doulat </center>**\n",
    "<center>Department of Computing </center>\n",
    "<center>East Tennessee State University</center>\n",
    "\n",
    "<hr style=\"border:2px solid lightblue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f647de7f",
   "metadata": {},
   "source": [
    "**In this assignment, you'll get to practice the concepts and skills covered in the first 2 modules (Modules 1&2). The main objective of this assignment is to implement and use some of the tools, algorithms, and techniques to represent and clean textual data..**\n",
    "\n",
    "\n",
    "\n",
    "**Guidelines**\n",
    "* Download `YelpReviews.csv` file from D2L. \n",
    "* Make sure to run all the code cells, otherwise you may get errors like `NameError` for undefined variables.\n",
    "* Do not change variable names, delete cells or disturb other existing code. It may cause problems during evaluation.\n",
    "* In some cases, you may need to add some code cells or new statements before or after the line of code containing the `???`.\n",
    "* Use markdown cells to write your discussions and reflections. \n",
    "\n",
    "**Procedure**\n",
    "* Save your work as `IPYNB` file named `Lab2.ipynb` and submit to D2L `Lab 2 - Text Cleaning (Dropbox)` by the due date.\n",
    "* As you go through this notebook, you will find the symbol `???` in certain places. To complete this assignment, you must replace all the `???` with appropriate values, expressions or statements to ensure that the notebook runs properly end-to-end.\n",
    "* Include your response for `Part 1` and `Part 2` in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e19a6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 1: Activity \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a1547",
   "metadata": {},
   "source": [
    "# Question 1: Reading the dataset \n",
    "<hr style=\"border:1px solid orange\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fee93f4",
   "metadata": {},
   "source": [
    "#### Read the content of the `YelpReviews.csv` into a dataframe `reviews_df` and perform the following: \n",
    "\n",
    "> **Q1.1.** Merge all the contents of the `text` column in the `reviews_df`. Then, convert all contents to lower case and store the results in a string called `reviews`. **Note:** *Make sure to split the reviews using whitespaces*.   \n",
    "\n",
    "> **Q1.2.** Using regular expressions, remove numeric characters and special characters (characters that are not alphabetic or numeric characters) from the `reviews` variable and store the result in a variable called `alphabetic_reviews`.\n",
    "\n",
    "> **Q1.3.** Tokenize the `alphabetic_reviews` into individual words or individual tokens and store the result into a list called `reviews_words`. \n",
    "\n",
    "> **Q1.4.** Remove the stopwords from the `reviews_words` list and store the results into a list called `no_stops_reviews_words`.\n",
    "\n",
    "> **Q1.5.** Perform stemming on the words in `no_stops_reviews_words` and store the results into a list called `stemmed_words`. \n",
    "\n",
    "> **Q1.6.** Find the top `50` most common words from the `stemmed_words` and store them into a list called `top_50_stemmed_words`.\n",
    "\n",
    "> **Q1.7.** Perform lemmatizations on the words in `no_stops_reviews_words` and store the results into a list called `lemmatized_words`.\n",
    "\n",
    "> **Q1.8.** Find the top `50` most common words from the `lemmatized_words` and store them into a list called `top_50_lemmatized_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b2f973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\JOSHIP1\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a11122-c287-4112-aa4c-270ac0fc90e1",
   "metadata": {},
   "source": [
    "### Q1.1. Merge all the contents of the text column in the reviews_df. Then, convert all contents to lower case and store the results in a string called reviews. \n",
    "##### Note: Make sure to split the reviews using whitespaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6211266-2513-44f7-bc09-5410b9d5fbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/26/2011</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/27/2011</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/14/2012</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/27/2010</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/5/2012</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>7/28/2012</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1/18/2012</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>11/16/2010</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>12/2/2012</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10/16/2010</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date               review_id  stars  \\\n",
       "0      1/26/2011  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1      7/27/2011  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2      6/14/2012  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3      5/27/2010  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4       1/5/2012  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "...          ...                     ...    ...   \n",
       "9995   7/28/2012  Ubyfp2RSDYW0g7Mbr8N3iA      3   \n",
       "9996   1/18/2012  2XyIOQKbVFb6uXQdJ0RzlQ      4   \n",
       "9997  11/16/2010  jyznYkIbpqVmlsZxSDSypA      4   \n",
       "9998   12/2/2012  5UKq9WQE1qQbJ0DJbc-B6Q      2   \n",
       "9999  10/16/2010  vWSmOhg2ID1MNZHaWapGbA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "0     My wife took me here on my birthday for breakf...  review   \n",
       "1     I have no idea why some people give bad review...  review   \n",
       "2     love the gyro plate. Rice is so good and I als...  review   \n",
       "3     Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4     General Manager Scott Petello is a good egg!!!...  review   \n",
       "...                                                 ...     ...   \n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "0     rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1     0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2     0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3     uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4     vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "...                      ...   ...     ...    ...  \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow     1       2      0  \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw     0       0      0  \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg     0       0      0  \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ     0       0      0  \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA     0       0      0  \n",
       "\n",
       "[10000 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reviews_df = pd.read_csv(\"YelpReviews.csv\")\n",
    "display(reviews_df)\n",
    "\n",
    "# Basic processing\n",
    "reviews = ' '.join(reviews_df['text'].astype(str))\n",
    "reviews = reviews.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda572f2-8d98-4183-9af4-a41ce3316542",
   "metadata": {},
   "source": [
    "### Q1.2. Using regular expressions, remove numeric characters and special characters (characters that are not alphabetic or numeric characters) from the reviews variable and store the result in a variable called alphabetic_reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0ffa2b2d-3470-4daf-9f7b-f41407aaff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabetic_reviews = re.sub(r'[^a-zA-Z\\s]', '', reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d779f7cb-0998-4c66-84a3-7f22cc0f4a6c",
   "metadata": {},
   "source": [
    "### Q1.3. Tokenize the alphabetic_reviews into individual words or individual tokens and store the result into a list called reviews_words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2239aecb-24d9-4cd1-8494-1431c0be132f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'wife', 'took', 'me', 'here', 'on', 'my', 'birthday', 'for', 'breakfast']\n"
     ]
    }
   ],
   "source": [
    "reviews_words = nltk.word_tokenize(alphabetic_reviews)\n",
    "print(reviews_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c7b65c-22cb-4657-96cb-907104b5aea7",
   "metadata": {},
   "source": [
    "### Q1.4. Remove the stopwords from the reviews_words list and store the results into a list called no_stops_reviews_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "774a8f93-48fb-451a-8054-5b4ccc324ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wife',\n",
       " 'took',\n",
       " 'birthday',\n",
       " 'breakfast',\n",
       " 'excellent',\n",
       " 'weather',\n",
       " 'perfect',\n",
       " 'made',\n",
       " 'sitting',\n",
       " 'outside',\n",
       " 'overlooking',\n",
       " 'grounds',\n",
       " 'absolute',\n",
       " 'pleasure',\n",
       " 'waitress',\n",
       " 'excellent',\n",
       " 'food',\n",
       " 'arrived',\n",
       " 'quickly',\n",
       " 'semibusy',\n",
       " 'saturday',\n",
       " 'morning',\n",
       " 'looked',\n",
       " 'like',\n",
       " 'place']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "no_stops_reviews_word = [word for word in review_words if word not in stop_words]\n",
    "display(no_stops_reviews_word[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44c17e3-8d9b-4952-940e-c38ce99d06a7",
   "metadata": {},
   "source": [
    "### Q1.5. Perform stemming on the words in no_stops_reviews_words and store the results into a list called stemmed_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "695a1954-3fa9-4195-bb21-c71453c74402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wife',\n",
       " 'took',\n",
       " 'birthday',\n",
       " 'breakfast',\n",
       " 'excel',\n",
       " 'weather',\n",
       " 'perfect',\n",
       " 'made',\n",
       " 'sit',\n",
       " 'outsid',\n",
       " 'overlook',\n",
       " 'ground',\n",
       " 'absolut',\n",
       " 'pleasur',\n",
       " 'waitress',\n",
       " 'excel',\n",
       " 'food',\n",
       " 'arriv',\n",
       " 'quickli',\n",
       " 'semibusi']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in no_stops_reviews_word]\n",
    "display(stemmed_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9019a02a-df8c-4a1b-9644-17e9e590bbd4",
   "metadata": {},
   "source": [
    "### Q1.6. Find the top 50 most common words from the stemmed_words and store them into a list called top_50_stemmed_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1aabdff2-2b0c-4783-a349-4a837f55780b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['place',\n",
       " 'good',\n",
       " 'food',\n",
       " 'like',\n",
       " 'great',\n",
       " 'go',\n",
       " 'get',\n",
       " 'time',\n",
       " 'one',\n",
       " 'order',\n",
       " 'realli',\n",
       " 'servic',\n",
       " 'would',\n",
       " 'love',\n",
       " 'tri',\n",
       " 'back',\n",
       " 'dont',\n",
       " 'also',\n",
       " 'make',\n",
       " 'nice',\n",
       " 'even',\n",
       " 'im',\n",
       " 'littl',\n",
       " 'well',\n",
       " 'restaur',\n",
       " 'look',\n",
       " 'want',\n",
       " 'ive',\n",
       " 'come',\n",
       " 'price',\n",
       " 'alway',\n",
       " 'best',\n",
       " 'us',\n",
       " 'got',\n",
       " 'thing',\n",
       " 'pretti',\n",
       " 'drink',\n",
       " 'know',\n",
       " 'menu',\n",
       " 'wait',\n",
       " 'much',\n",
       " 'chicken',\n",
       " 'think',\n",
       " 'eat',\n",
       " 'bar',\n",
       " 'peopl',\n",
       " 'didnt',\n",
       " 'say',\n",
       " 'first',\n",
       " 'night']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stemmed_word_counts = Counter(stemmed_words)\n",
    "top_50_stemmed_words = [word for word, _ in stemmed_word_counts.most_common(50)]\n",
    "display(top_50_stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945bce8-b25c-4bd6-b1ac-b14c7cd6d445",
   "metadata": {},
   "source": [
    "### Q1.7. Perform lemmatizations on the words in no_stops_reviews_words and store the results into a list called lemmatized_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67337454-8d49-4ed1-90f9-03645ed4c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(word) for word in no_stops_reviews_word]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14533c6c-b60a-428e-982d-34dd321a2d98",
   "metadata": {},
   "source": [
    "### Q1.8. Find the top 50 most common words from the lemmatized_words and store them into a list called top_50_lemmatized_words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3816afe7-8926-4d57-ab7e-6ea5832876b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['place',\n",
       " 'good',\n",
       " 'food',\n",
       " 'great',\n",
       " 'like',\n",
       " 'time',\n",
       " 'one',\n",
       " 'get',\n",
       " 'go',\n",
       " 'really',\n",
       " 'service',\n",
       " 'would',\n",
       " 'back',\n",
       " 'dont',\n",
       " 'also',\n",
       " 'love',\n",
       " 'im',\n",
       " 'little',\n",
       " 'nice',\n",
       " 'well',\n",
       " 'restaurant',\n",
       " 'ive',\n",
       " 'make',\n",
       " 'always',\n",
       " 'even',\n",
       " 'best',\n",
       " 'u',\n",
       " 'got',\n",
       " 'thing',\n",
       " 'pretty',\n",
       " 'menu',\n",
       " 'much',\n",
       " 'try',\n",
       " 'chicken',\n",
       " 'order',\n",
       " 'know',\n",
       " 'ordered',\n",
       " 'price',\n",
       " 'bar',\n",
       " 'people',\n",
       " 'drink',\n",
       " 'come',\n",
       " 'didnt',\n",
       " 'first',\n",
       " 'night',\n",
       " 'think',\n",
       " 'could',\n",
       " 'never',\n",
       " 'better',\n",
       " 'went']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemmatized_word_counts = Counter(lemmatized_words)\n",
    "top_50_lemmatized_words = [word for word, _ in lemmatized_word_counts.most_common(50)]\n",
    "display(top_50_lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c4859",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Part 2: Reflection\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f41c86",
   "metadata": {},
   "source": [
    "As a second step—after answering the questions, include the following:\n",
    "1. A reflection of your experience performing the activity. \n",
    "2. A reflection on the importance of learning this activity.\n",
    "**Note:** include your reflection in this notebook as markdown cells. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ec951",
   "metadata": {},
   "source": [
    "### A reflection of your experience performing the activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1830587-472f-4417-9bd3-82503f6dd83d",
   "metadata": {},
   "source": [
    "I performed text cleaning on the YelpReviews dataset which was interesting and challenging. This activity involved different tasks, from reading the data and preprocessing to removing stop words and stemming the words. I understood the whole process and flow of the activity. I found the activity of removing stop words and stemming and lemmatizing the words particularly insightful. I like how this task did not include complex coding. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b99298a-b6c4-4c28-84d3-33ac7be59970",
   "metadata": {},
   "source": [
    "### A reflection on the importance of learning this activity. Note: include your reflection in this notebook as markdown cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b569965-5fdd-4925-a3e1-55f902170878",
   "metadata": {},
   "source": [
    "In the field in Natural Language Processing, learning how to process and analyze text data is essential. The tasks of removing and cleaning the text, removing stop words, stemming, and lemmatizing the text are foundational and essential. The insights extracted after performing these tasks can applied in many areas like sentiment analysis, recommendation systems and so on. This activity provides technical know-how to clean and process the data but also uncover the importance of context in the unstructured text. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844c3dbe",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Submission\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd22e1a",
   "metadata": {},
   "source": [
    "Submit **Lab2.ipynb** to the **Lab 2 - Text Cleaning (Dropbox)** on D2L by the due date. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053c344",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "# Grading Rubric\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c85704",
   "metadata": {},
   "source": [
    "|Criterion\t|Excellent\t|Good\t|Average\t|Below Average\t|Poor\t|No Attempt|\n",
    "|:--\t|:--\t|:--\t|:--\t|:-- \t|:--\t|:-- |\n",
    "|**Part 1:** Activity-Question 1.1|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.2|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.3|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.4|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.5|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.6|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.7|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 1:** Activity-Question 1.8|\t**10 points**- Completes all aspects of the question correctly\t|**8 points**- Completes most aspects of the question correctly |**6 points**- Completes aspects of the question  correctly, and some incorrectly\t|**4 points**- Completes most aspects of the question  incorrectly or does not attempt many aspects|\t**2 points**- Minimal effort or completes a few aspects of the question or very few correctly|**0 points**- Did not complete the question|\n",
    "|**Part 2:** Reflection|**10 points**- Reflection clearly ties to the module content; experience and importance clearly laid out|**8 points**- Reflection mostly ties to the module content; experience & importance are discussed|**6 points**- Reflection ties minimally to the module content; experience & importance are discussed but not thoroughly|**4 points**- Reflection does not tie to the module content; experience & importance are minimally discussed|**2 points**- Minimal effort to tie to content; minimal effort to describe experience/ importance|**0 points**- Did not complete the reflection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26913da0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "214.052px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
